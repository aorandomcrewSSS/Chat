# SYS_AUTO_GRANT_SELECT_PRIVELEGES

## Описание

`SYS_AUTO_GRANT_SELECT_PRIVELEGES` — это DAG, который автоматически выдает права `SELECT` на новые таблицы и представления в Greenplum пользователям, чьи роли соответствуют шаблону: *_develop_*

---

## Расписание

DAG выполняется ежедневно два раза в сутки по cron:

- в 06:00
- в 13:00

---

## Подключения

DAG работает с двумя подключениями Airflow:

- `greenplum`
- `greenplum_cloud`

В рамках каждого подключения выполняются свои задачи по поиску таблиц и выдаче прав.

---

## Принцип работы

DAG состоит из двух основных шагов, которые выполняются последовательно для каждого подключения.

---

### 1. Поиск объектов для выдачи прав

Задача `get_table_name_<connection>` выполняет SQL-запрос, который определяет таблицы и представления, на которые ещё не выданы привилегии `SELECT` ролям, оканчивающимся на `_develop_`.

Объекты выбираются из схем:

- `grp_%`
- `dwh_%`
- `grp_dev`

При этом исключаются:

- партиции (`%_prt_%`)
- таблицы, на которые grant уже существует

Пример SQL-запроса:

```sql
select nms.nspname, cl.relname
from pg_class as cl
inner join pg_namespace nms on nms.oid = cl.relnamespace
    and (nms.nspname like 'grp_%'
        or nms.nspname like 'dwh_%'
        or nms.nspname = 'grp_dev')
left join information_schema.role_table_grants rtg
    on cl.relname = rtg.table_name
    and nms.nspname = rtg.table_schema
    and grantee like '%_develop_%'
where cl.relkind in ('r', 'v', 'm')
    and cl.relname not like '%_prt_%'
    and rtg.table_name is null;
```

Результат запроса имеет формат:
(schema_name, table_name)

### 2. Выдача прав
Задача grant_select_<connection> получает список выявленных объектов и для каждого из них выполняет вызов
`select dwh_meta.f_grant_default_privs('<schema>', '<table>');`

Эта функция отвечает за выдачу стандартных прав, включая SELECT, нужным пользователям.

После выполнения каждого SQL-вызова выполняется COMMIT.


# SYS_AUTO_REMOVE_HOSTS_LOGS

## Описание

`SYS_AUTO_REMOVE_HOSTS_LOGS` — это DAG, который автоматически очищает директорию системных логов Airflow от устаревших файлов и удаляет пустые директории.  

---

## Расписание

DAG выполняется каждые 3 дня, начиная с:

- 29.07.2025 11:00 UTC

---

## Среды выполнения

В зависимости от имени хоста применяется разный срок хранения логов:

| Hostname           | Среда | Срок хранения |
|--------------------|-------|---------------|
| `msk-dad-air-s1`   | DEV   | 15 дней       |
| `msk-pad-air-s1`   | PROD  | 30 дней       |

---

## Принцип работы

Задача `clear_logs`:

- определяет среду по hostname,
- выбирает срок хранения (`15` дней для DEV, `30` — для PROD),
- удаляет в `/var/log/airflow`:
  - файлы старше установленного срока,
  - пустые директории, оставшиеся после удаления файлов,
- выводит в лог статистику с количеством удалённых элементов.

Пример выполняемого кода:

```bash
if [ $(hostname) = 'msk-dad-air-s1' ]; then
    deleted_days=15
else
    deleted_days=30
fi

echo "INFO: Current host is $(hostname), files older than $deleted_days days will be deleted";

deleted_files=$(find /var/log/airflow -type f -mtime +$deleted_days -print -delete | wc -l)
echo "INFO: Deleted $deleted_files files";

deleted_dirs=$(find /var/log/airflow -type d -empty -print -delete | wc -l)
echo "INFO: Deleted $deleted_dirs empty directories";
```

## SYS_RETRIGGER_FAILED_DAGS

`SYS_RETRIGGER_FAILED_DAGS` — это DAG, который автоматически находит и перезапускает DAG Run’ы других DAG’ов по заданным тегам и статусу. DAG помогает оперативно повторно выполнить неуспешные или успешные DAG Run’ы без ручного вмешательства.

---

## Расписание

DAG запускается вручную (`schedule_interval=None`). Одновременное количество активных запусков ограничено одним (`max_active_runs=1`).

---

## Параметры запуска

DAG принимает следующие параметры через `dag_run.conf`:

* `tag` — строка или список тегов DAG’ов, которые нужно обработать (например `"core, cloud"` или `["core","cloud"]`).
* `status` — фильтр по статусу последнего DAG Run:

  * `true` — перезапускать только `FAILED`,
  * `false` — перезапускать только `SUCCESS`.
* `limit` — максимальное количество перезапусков за один запуск DAG, по умолчанию `50`.

---

## Принцип работы

DAG состоит из одной основной задачи `find_and_retrigger`, которая выполняет следующие шаги:

1. **Определение DAG’ов для перезапуска**

   * Получает список DAG’ов по указанным тегам.
   * Игнорирует DAG’ы без предыдущих запусков.
   * Пропускает DAG’ы, которые приостановлены (`is_paused=True`).
   * Фильтрует DAG’ы по статусу последнего DAG Run, если указан параметр `status`.

2. **Проверка доступных слотов в пулах**

   * Для каждого DAG Run проверяются все TaskInstance’ы и их пул.
   * Учитываются зарезервированные слоты для предотвращения превышения лимитов пула.
   * Если в пуле недостаточно слотов — DAG пропускается.

3. **Перезапуск DAG Run**

   * Состояние DAG Run устанавливается в `QUEUED`.
   * Состояния всех тасков сбрасываются (`state=None`).
   * Обновляются локально зарезервированные слоты в пулах.
   * Поддерживается ограничение по количеству перезапусков (`limit`).

4. **Логирование и отчет**

   * Для каждого перезапуска выводится информация: DAG ID, execution_date, причина пропуска, если перезапуск невозможен.
   * В конце логируется общее количество перезапущенных DAG Run’ов.

---

## Особенности

* Поддержка нескольких тегов через запятую или список.
* Ограничение по максимальному числу перезапусков за один запуск DAG.
* Проверка состояния пула для предотвращения блокировок задач.
* Пропуск DAG’ов, которые уже находятся в очереди (`QUEUED`).




